---
title: "Futures нулевой стоимости в Rust"
author: Aaron Turon (перевёл Сергей Ефремов)
categories: обучение
excerpt: >
    Новые возможности Rust по использованию Futures.
---

Это перевод [статьи](http://aturon.github.io/blog/2016/08/11/futures/).
    
   
Одним из основных пробелов в экосистеме Rust был рассказ о быстром и
продуктивном `асинхронном вводе/выводе`. У нас есть прочный фундамент из
библиотеки [mio](http://github.com/carllerche/mio), но она очень низкоуровневая:
приходится вручную создавать конечные автоматы и жонглировать обратными
вызовами.

Нам бы хотелось чего-нибудь более высокоуровнего, с лучшей эргономикой, но чтобы
оно обладало хорошей `компонуемостью`, поддерживая экосистему асинхронных
абстракций, работающих вместе. Звучит очень знакомо: ту же цель преследовало
внедрение `futures` (или promises) во [многие языки](https://en.wikipedia.org/wiki/Futures_and_promises#List_of_implementations), поддерживающие синтаксический
сахар ввиде `async/await` на вершине.

Основным принципом Rust является возможность строить 
[абстракции с нулевой стоимостью](https://blog.rust-lang.org/2015/05/11/traits.html),
что приводит нас к дополнительной цели нашего рассказа о async I/O: в идеале
абстракции как futures должны компилироваться в что-то эквивалентное коду в виде
конечных- автоматов-и-жонглированием-обратными-вызовам, который мы сегодня пишем
(без дополнительных накладных расходов во времени исполнения).

Последние несколько месяцев, Alex Crichton и Я разрабатывали [библиотеку futures
нулевой стоимости](https://github.com/alexcrichton/futures-rs) для Rust, ту,
которая, мы считаем, позволит достичь этих целей. (Спасибо Carl Lerche, Yehuda
Katz, и Nicholas Matsakis за понимание на все пути.)

Сегодня мы рады начать серию статей о новой библиотеке. В этом посте
рассказываются самые яркие моменты, ключевые идеи и несколько предварительных
тестов. Дальнейшие посты покажут, как возможности Rust используются в
проектировании этих абстракций с нулевой стоимостью. Также вас уже ждет
[TUTORIAL](https://github.com/alexcrichton/futures-rs/blob/master/TUTORIAL.md).

#### Почему async I/O?

Прежде, чем копать futures, полезно будет рассказать немного о прошлом.

Начнем с маленького кусочка I/O, который вы хотели бы выполнить: чтение
определенного количества байт из сокета. Rust предоставляет функцию
[read_exact](https://static.rust-
lang.org/doc/master/std/io/trait.Read.html#method.read_exact) для этого:

```rust
// reads 256 bytes into `my_vec`
socket.read_exact(&mut my_vec[..256]);
```

Быстрый вопрос: что происходит, если у нас еще недостаточно байт получено от сокета?

Для сегодняшнего Rust ответ такой: текущий поток блокируется, засыпая пока не
будут получены еще байты. Но так было не всегда.

Давным давно в Rust была реализована модель `зеленых потоков`, не такая как в
Go. Вы могли завести огромное количество легковесных `заданий`, которые потом
были распределены по реальным потокам ОС (иногда такая система называется `M:N
threading`). В модели зеленых потоков функция `read_exact` заблокирует текущее
`задание`, но не поток ОС; вместо этого, планировщик заданий переключится на
другое задание. Это великолепно, можно использовать огромное количество заданий,
большинство из которых блокировано, используя небольшое количество потоков ОС.

Проблема в том, что модель зеленых потоков [шла в
разрез](https://mail.mozilla.org/pipermail/rust-dev/2013-November/006314.html)
амбициям Rust по полной замене Си, без какой-либо дополнительно навязанной
системы выполнения или увеличения цены FFI: мы так и не нашли стратегию их
реализации, которая бы не накладывала дополнительных серьезных глобальных
расходов. Вы можете почитать больше [в RFC, в котором были удалены зеленые
потоки](https://github.com/aturon/rfcs/blob/remove-runtime/active/0000-remove-
runtime.md).

Итак, если мы хотим держать большое число одновременных подключений, многие из
которых ждут I/O, но при этом держать число потоков ОС на минимуме, что еще мы
можем сделать?

Асинхронный I/O - вот ответ, на самом деле он также используется и для
реализации  зеленых потоков.

В двух словах, благодаря async I/O вы можете `попытаться` выполнить операцию I/O
без блокировки. Если она не может мгновенно выполниться, можно попробовать через
какое-то время. Для того, чтобы это работало, ОС предоставляет различные
инструменты, как [epoll](https://en.wikipedia.org/wiki/Epoll), позволяющие
запросить, какие объекты из огромного списка I/O объектов `готовы` к чтению или
записи - по существу это API, которое предоставляет
[mio](http://github.com/carllerche/mio).

Проблема в том, что надо выполнить много болезненной работы по слежению за
списком интересных вам I/O событий, и передать эти события правильным обратным
вызовам (не говоря уже о программировании чисто callback-driven способом). Это
одна из ключевых проблем, которую решают futures.</p>

#### Futures

Итак, `что` такое future?

По существу, future представляет собой значение, которое может быть еще не
готово. Обычно, future становится `законченным` (значение готово) после какого-
то произошедшего события где-то в другом месте. Мы рассматривали их со стороны
базового I/O, вы можете использовать future для представления огромного числа
различных событий, например:


- *Запрос к БД*, который выполняется в пуле потоков. Если запрос выполнился,
future станет законченным, а в его значении будет результат запроса.
- *Выполнение RPC* на сервере. Если сервер ответил, future станет законченным, а
в его значении будет ответ сервера.
- *Таймаут*. Если время вышло, future станет законченным, а его значением будет 
() (единичное значение в Rust).
- *Долго выполняющееся CPU-затратное задание*, выполняющееся в пуле потоков.
Когда задание заканчивается, future станет законченным, а его значением будет 
значение задания.
- *Чтение байт из сокета*. Если байты готовы, future станет законченным - и в 
зависимости от стратегии буферизации, байты могут быть получены напрямую или 
записаны в дополнительный уже существующий буфер.

И так далее. Фишка futures в том, что их можно применять к асинхронным событиям
любой формы и размера. Асинхронность отражается в факте правильного получения
`future`, без блокировки, при том, что `значение`, которое представляет future,
будет готовым только в какой то момент в будущем (future).

В Rust мы представляем futures в виде [типажа](http://alexcrichton.com/futures-rs/futures/trait.Future.html)
(например, интерфейса), грубо говоря:

```rust
trait Future {
    type Item;
    // ... все остальное опущено ...
}
```


*Item* говорит, какой тип значения future вернет после выполнения.

Возвращаясь к нашему ранее приведенному списку примеров, напишем несколько
функций, возвращающих различные futures (используя синтаксис
[impl](https://github.com/rust-lang/rfcs/pull/1522)):

```rust
// Получение строки из таблицы по id, возвращает строку после выполнения
fn get_row(id: i32) -> impl Future<Item = Row>;

// Вызов RPC, которая возвращает i32 после выполнения
fn id_rpc(server: &RpcServer) -> impl Future<Item = i32>;

// Запись строки в TcpStream, возвращает stream после выполнения
fn write_string(socket: TcpStream, data: String) -> impl Future<Item = TcpStream>;
```

Все эти функции `немедленно` вернут future, случилось или нет событие, которое
future представляет; функции неблокирующие.

Все становится еще интереснее с futures, когда вы сочетаете их. Существует
бесчисленное количество вариантов их сочетания, например:

- [Sequential composition](http://alexcrichton.com/futures-rs/futures/trait.Future.html#method.and_then): `f.and_then(|val| some_new_future(val))`.
Возвращает вам future, который выполняет future `f`, берет `val`, который он
создает, и строит еще один future `some_new_future(val)`, затем выполняет его.

- [Mapping](http://alexcrichton.com/futures-rs/futures/trait.Future.html#method.map):
`f.map(|val| some_new_value(val))`. 
Возвращает вам future, который выполняет future `f` и применяет его к результату
`some_new_value(val)`.

- [Joining](http://alexcrichton.com/futures-rs/futures/trait.Future.html#method.join):`f.join(g)`. 
Возвращает вам future, который выполняет futures `f` и `g` в параллель, и
заканчивается, когда оба из них закончатся, возвращая оба их значения.

- [Selecting](http://alexcrichton.com/futures-rs/futures/trait.Future.html#method.select):`f.select(g)`.
Возвращает вам future, который выполняет futures `f` и `g` в параллель, и
заканчивается, когда `один` из них закончится, возвращая его значения и другой
future. (Хотите добавить таймаут к любому future? Просто выполните `select`
этого future и таймаут future!)

В качестве простого примера использования futures выше, можем написать что-то вроде такого:

```rust
id_rpc(&my_server).and_then(|id| {
    get_row(id)
}).map(|row| {
    json::encode(row)
}).and_then(|encoded| {
    write_string(my_socket, encoded)
})
```

Смотри [этот код](https://github.com/alexcrichton/futures-rs/blob/master/futures-minihttp/techempower2/src/main.rs) с более конкретными примерами.


Это неблокирующий код, который проходит через несколько состояний: сначала мы
делаем вызов RPC  для получения ID; затем смотрим соответствующую строку;
кодируем ее в json; записываем ее в сокет. *Под капотом этого кода находится
конечный автомат, меняющий свое состояние с помощью обратных вызовов (без
дополнительных накладных расходов)*, хотя по стилю этот код очень похож на
`блокирующий` код. (Rustaceans заметят, что эта история очень похожа на историю
с `Iterator` в стандартной библиотеке.) Эргономичный, высокоуровневый код,
компилирующийся в конечный-автомат-с-обратными-вызовами: вот к чему мы пришли
наконец!

Кроме того, стоит учесть, что каждый из future, используемых здесь, может прийти
из другой библиотеки. Абстракции future позволяют их легко объединять вместе.

#### Streams

Но погодите, есть еще кое-что! Когда вы начнете использовать комбинаторы для
future, вы не только добьетесь равенства с простым блокирующим кодом, но сможете
делать вещи гораздо более хитрые или те, что было бы очень трудно написать по-
другому. Для примера нам нужен еще один концепт: streams.

Futures предназначены для получения `одного` значения после того, как произойдет
какое-то событие, но часто источники событий периодически создают `поток`
значений. Например, входящее TCP соединение или входящие запросы по сокету
являются сами по себе потоками.

Библиотека futures также включает в себя типаж [Stream](http://alexcrichton.com
/futures-rs/futures/stream/trait.Stream.html), который очень похож на futures,
но настраивается на создание последовательности значений с течением времени.
Внутри есть набор комбинаторов, некоторые из которых работают с futures.

Например, если `s` это поток, то можно написать:

```rust
s.and_then(|val| some_future(val))
```

Этот код даст вам новый поток, который работает так: сначала достается первое
значение `val` из `s`, вычисляется `some_future(val)` из него, затем выполняется
этот future и возвращается его значение - затем все опять по кругу для
вычисления следующего значения из потока.

Рассмотрим реальный пример:

```rust
// Обладая объектом I/O `input`, создаем поток запросов
let requests = ParseStream::new(input);

// Для каждого запроса запускаем нашу функцию сервиса `process` для обработки 
// запроса и создаем ответ
let responses = requests.and_then(|req| service.process(req));

// Создаем новый future, который запишет каждый наш ответ в объект I/O `output`
StreamWriter::new(responses, output)
```

Здесь мы написали ядро простого сервера работающего на потоках. Это, конечно, не
космонавтика, но все равно довольно круто манипулировать значениями `responses`,
которые представляют в целом, что создает сервер.

Сделаем вещи еще интереснее. Предположим, что протокол обмена конвейерный, т.е.,
что клиент может послать дополнительные запросы в сокет до того, как выполняться
ранее посланные. На самом деле мы хотим, чтобы обработка запросов шла
последовательно, но тут имеет место и использование параллелизма: мы могли бы
прочесть и `обработать` несколько запросов вперед, пока обрабатывается текущий
запрос. Сделать это также просто как добавить еще один комбинатор в нужное
место:

```rust
let requests = ParseStream::new(input);
let responses = requests.map(|req| service.process(req)).buffered(32); // <--
StreamWriter::new(responsesm, output)
```

Комбинатор [buffered](http://alexcrichton.com/futures-rs/futures/stream/trait.Stream.html#method.buffered) берет поток `futures` и
буферизирует их до какого-то конечного числа. Буферизация потока означает, что
будет с жадностью выдергиваться большее, чем запрошено количество объектов, а
полученные futures будут прятаться в буфер для дальнейшей обработки. В данном
случае это означает, что будет читаться и обрабатываться до 32 дополнительных
запросов в параллель, пока происходит обработка текущего запроса.

Это относительно простые примеры использования futures и streams, но мы
надеемся, что они объяснят, как комбинаторы могут сильно помочь вам в
высокоуровневом асинхронном программировании.

#### Нулевая стоимость?

Я несколько раз утверждал, что наша библиотека futures предоставляет абстракции
с нулевой стоимостью, в которых компиляция происходит в что-то очень близкое к
коду конечного автомата, который вы бы написали от руки. Чтобы быть более
конкретным:


- Ни один из комбинаторов future не налагает никакую аллокацию в памяти. Когда мы 
создаем цепочки, используя `and_then`, мы не только не аллоцируем ничего, мы на
самом деле строим большой `enum`, представляющий конечный автомат. (Одна 
аллокация нужна для задания, которое обычно используется для одно на соединение.)

- Когда происходит событие, нужен только один динамический вызов.

- Практически отсутствуют затраты, налагаемые синхронизацией; если вы хотите 
связать данные, находящиеся в вашей петле события, и иметь доступ к ним в 
однопоточном виде из futures, мы даем вам инструменты для этого.


И так далее. Будущие блог-посты погрузят вас глубже в детали этих утверждений и
покажут, как мы использовали преимущества Rust для получения нулевой цены.

Но лучше один раз увидеть, чем сто раз услышать. Мы написали простой HTTP server
framework [minihttp](https://github.com/alexcrichton/futures-rs/tree/master/futures-minihttp),
который поддерживает конвейерную обработку и TLS. *Этот сервер использует 
futures на каждом уровне своей реализации, начиная с чтения байт из сокета и 
заканчивая обработкой потоков запросов*. Кроме того, что было очень приятно 
писать сервер, это дало возможность провести сильные стресс тесты накладных 
расходов абстракций futures.

Чтобы оценить эти накладные расходы, мы реализовали [TechEmpower "plaintext" benchmark](https://www.techempower.com/benchmarks/#section=data-r12&amp;hw=peak&amp;test=plaintext). 

Этот микротест проверяет "hello world" HTTP сервер, кидая большое число
параллельных и конвейерных запросов ему. Из-за того, что работа, которую
выполняет этот сервер по обработке запроса тривиальна, производительность в
большой степени зависит от базовых накладных расходов server framework (в нашем
случае, futures framework).

TechEmpower используется для сравнения большого количества веб фреймворков на
разных языках. Мы [сравнили](https://github.com/alexcrichton/futures-
rs/blob/master/futures-minihttp/README.md) minihttp с несколькими лучшими
представителями:

- [rapidoid](https://github.com/TechEmpower/FrameworkBenchmarks/tree/master/frameworks/Java/rapidoid),
Java framework, который был первым в последнем раунде официальных тестов.
- [Go](https://github.com/TechEmpower/FrameworkBenchmarks/tree/master/frameworks/Go/go-std),
реализация, использующая поддержку HTTP из стандартной библиотеки Go.
- [fasthttp](https://github.com/TechEmpower/FrameworkBenchmarks/tree/master/frameworks/Go/fasthttp), 
конкурент стандартной библиотеки Go.
- [node.js](https://github.com/TechEmpower/FrameworkBenchmarks/tree/master/frameworks/JavaScript/nodejs).

Вот результаты, в количестве обслуженных "Hello world!" в секунду на 8 ядрах
Linux машины:

![alt](https://aturon.github.io/blog/public/bench-pipelined.png)

Кажется, можно уверенно сказать, что futures не вносят существенных
дополнительных расходов.

*Дополнительно*: для предоставления дополнительных свидетельств, мы [добавили
сравнение](https://github.com/alexcrichton/futures-rs/blob/master/futures-
minihttp/README.md) minihttp с версией с вручную созданным конечным автоматом на 
Rust (см. "raw mio" по ссылке). Они находятся в 0.3% друг от друга.

#### Будущее

Итак, завершим наше ураганное введение в futures с нулевой стоимостью в Rust.
Рассмотрим больше деталей в дальнейших постах.

На текущий момент библиотека достаточно готова к использованию, и довольно
тщательно документирована; в нее входит
[tutorial](https://github.com/alexcrichton /futures-rs/blob/master/TUTORIAL.md)
и несколько примеров, включающих:

- простой [TCP echo server](https://github.com/alexcrichton/futures-rs/blob/master/futures-mio/src/bin/echo.rs)
- эффективный [SOCKSv5 proxy server](https://github.com/alexcrichton/futures-rs/blob/master/futures-socks5/src/main.rs)
- `minihttp`, высокоэффективный [HTTP server](https://github.com/alexcrichton/futures-rs/tree/master/futures-minihttp), поддерживающий TLS и использующий [Hyper's parser](https://crates.io/crates/httparse)
- пример [использования minihttp](https://github.com/alexcrichton/futures-rs/tree/master/futures-minihttp/tls-example) для TLS соединений,


а также разные интеграции, т.е. основанные на futures интерфейсы к
[curl](http://alexcrichton.com/futures-rs/futures_curl). Мы активно работаем с
несколькими людьми из сообщества Rust по интегрированию с их работами; если вам
интересно, пожалуйста, связывайтесь с Alex или со мной!

Если вам нужно низкоуровневое I/O программирование с futures, можете
использовать [futures-mio](http://alexcrichton.com/futures-rs/futures_mio) для
этого на mio. Мы считаем, что это перспективное направление для перевода
асинхронного программирования I/O в общем в Rust, последующие посты будут
детально рассказывать об этом.

Кроме того, если вы просто хотите обрабатывать HTTP, вы можете работать с
[minihttp](https://github.com/alexcrichton/futures-rs/tree/master/futures-
minihttp) предоставляя `службу`: функцию, котороая принимает HTTP запрос, и
возвращает `future` HTTP ответа. Этот вид абстракций RPC/служб открывает двери
написанию огромного числа повторного использования "middleware" для серверов, и
нашел отражение в библиотеке Twitter
[Finagle](https://twitter.github.io/finagle) на Scala; он также используется в
библиотеке Facebook [Wangle](https://github.com/facebook/wangle). В мире Rust
уже в разработке библиотека [Tokio](https://medium.com/@carllerche /announcing-
tokio- df6bb4ddb34#.g9ugbqg71), которая строит абстракцию общей службы с помощью
нашей библиотеки futures, и может играть роль, похожую на Finagle.

Предстоит еще очень много работы:

- Для начала, мы бы очень хотели получить отзыв об абстракциях future и stream,
также есть некоторые особые детали для некоторых комбинаторов, в которых мы не 
уверены.
- Во-вторых, пока мы создали несколько абстракций future вокруг базовых 
принципов I/O, есть еще много мест, где их можно использовать, и мы будем рады 
получить помощь в этом.
- Обобщая все, надо написать еще бесконечное число "привязок" futures к разным 
библиотекам (как на Си так и на Rust); Если у вас есть библиотека, к которой вы 
хотите привязать futures, мы готовы помочь!
- В глобальной перспективе следующим очевидным шагом будет исследование 
async/await нотации поверх futures, может быть также как предложено в [Javascript](https://tc39.github.io/ecmascript-asyncawait). Но для начала мы хотим получить побольше опыта, 
используя futures напрямую как библиотеку, перед тем, как решимся на такой шаг.

Если вас что-то заинтересовало, мы готовы ответить на любые вопросы - мы это
acrichto и aturon на [каналах IRC](https://www.rust-lang.org/en-US/community.html) по Rust. Присоединяйтесь!
